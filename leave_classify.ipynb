{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-03T08:33:18.027816Z",
     "start_time": "2024-06-03T08:33:12.457176Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LeaveDataDataset(Dataset):\n",
    "    def __init__(self,train_csv_path,mode='train',train_ratio=0.8,\n",
    "                 resize_height=256,resize_width=256):\n",
    "        self.resize_height = resize_height\n",
    "        self.resize_width = resize_width\n",
    "        self.train_ratio = train_ratio\n",
    "        self.data = pd.read_csv(train_csv_path)\n",
    "        self.mode = mode\n",
    "        self.data_len = len(self.data)\n",
    "        self.train_len = int(self.data_len * self.train_ratio)\n",
    "        if mode == 'train':\n",
    "            self.image = np.asarray(self.data.iloc[:self.train_len, 0])\n",
    "            self.label = np.asarray(self.data.iloc[:self.train_len, 1])\n",
    "        elif mode == 'valid':\n",
    "            self.image = np.asarray(self.data.iloc[self.train_len:, 0])\n",
    "            self.label = np.asarray(self.data.iloc[self.train_len:, 1])\n",
    "        elif mode == 'test':\n",
    "            self.image =np.asarray(self.data.iloc[:, 0])\n",
    "        self.len = len(self.image)\n",
    "        print('Finished reading the {} set of Leaves Dataset ({} samples found)'\n",
    "              .format(mode, self.len))\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image[index]\n",
    "        image = Image.open(image_path)\n",
    "        # if image.mode != 'L':\n",
    "        #     image = image.convert('L')\n",
    "        if self.mode == 'train':\n",
    "            transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                            transforms.RandomHorizontalFlip(p=0.5), \n",
    "                                            transforms.RandomVerticalFlip(p=0.5),\n",
    "                                            transforms.ToTensor()])\n",
    "        else:\n",
    "            transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                            transforms.ToTensor()])\n",
    "        img = transform(image)\n",
    "        if self.mode == 'test':\n",
    "            return img\n",
    "        else:\n",
    "            label = self.label[index]\n",
    "            label_num = class_to_num[label]\n",
    "            return img,label_num\n",
    "    def __len__(self):\n",
    "        return self.len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T08:33:18.043782Z",
     "start_time": "2024-06-03T08:33:18.031780Z"
    }
   },
   "id": "b26b8af1a68aaa0a",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, input_channels, num_channels,use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "def resnet18(num_classes, in_channels=1):\n",
    "    def resnet_block(in_channels, out_channels, num_residuals,\n",
    "                     first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(Residual(in_channels, out_channels,use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(Residual(out_channels, out_channels))\n",
    "        return nn.Sequential(*blk)\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU())\n",
    "    net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
    "    net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
    "    net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
    "    net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n",
    "    net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1,1)))\n",
    "    net.add_module(\"fc\", nn.Sequential(nn.Flatten(),\n",
    "                                       nn.Linear(512, num_classes)))\n",
    "    return net"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T08:33:18.074781Z",
     "start_time": "2024-06-03T08:33:18.045784Z"
    }
   },
   "id": "aac520e4940105e4",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_leaf(net, num_epochs, lr, device,best_acc):\n",
    "    print(device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    net = net.to(device)    \n",
    "    train_dataset = LeaveDataDataset(train_path,mode='train')\n",
    "    val_dataset = LeaveDataDataset(train_path,mode='valid')\n",
    "\n",
    "    train_iter = DataLoader(dataset=train_dataset,batch_size=batch_size, shuffle=True)\n",
    "    val_iter = DataLoader(dataset=val_dataset,batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        print('Train Epoch: {}/{}'.format(epoch, num_epochs),'train len: {}'.format(len(train_iter)))\n",
    "        train_loss, train_acc, n = 0.0, 0.0, 0   \n",
    "        for X, y in tqdm(train_iter):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += l.item() * y.shape[0]\n",
    "            train_acc += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        train_loss /= n\n",
    "        train_acc /= n\n",
    "        print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}\")\n",
    "        \n",
    "        net.eval()\n",
    "        print('Val Epoch: {}/{}'.format(epoch, num_epochs),'val len: {}'.format(len(val_iter)))\n",
    "        val_loss, val_acc, m = 0.0, 0.0, 0\n",
    "        for X, y in tqdm(val_iter):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            with torch.no_grad():\n",
    "                y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            val_loss += l.item() * y.shape[0]\n",
    "            val_acc += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            m += y.shape[0]\n",
    "        val_loss /= m\n",
    "        val_acc /= m\n",
    "        print(f\"Epoch {epoch}: Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), './working/leaf_resnet18.pth')\n",
    "            print('saving model with acc {:.3f}'.format(best_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T08:33:18.090781Z",
     "start_time": "2024-06-03T08:33:18.076785Z"
    }
   },
   "id": "800ae01ee96e4030",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size=16\n",
    "lr=0.05\n",
    "best_acc = 0.1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'\n",
    "# data = pd.read_csv('train.csv')\n",
    "# label_all = sorted(list(set(data.iloc[:,1])))\n",
    "# n_classes = len(label_all)\n",
    "# class_to_num = dict(zip(label_all,range(n_classes)))\n",
    "# np.save('class_to_num.npy',class_to_num)\n",
    "# num_to_class = dict(zip(range(n_classes),label_all))\n",
    "# np.save('num_to_class.npy',num_to_class)\n",
    "class_to_num = np.load('class_to_num.npy', allow_pickle=True).item()\n",
    "num_to_class = np.load('num_to_class.npy', allow_pickle=True).item()\n",
    "n_classes = len(class_to_num)\n",
    "model = resnet18(num_classes = n_classes,in_channels=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T08:33:18.200856Z",
     "start_time": "2024-06-03T08:33:18.093782Z"
    }
   },
   "id": "ccf96831afa909e9",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Finished reading the train set of Leaves Dataset (14682 samples found)\n",
      "Finished reading the valid set of Leaves Dataset (3671 samples found)\n",
      "Train Epoch: 0/20 train len: 918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [25:51<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss=4.5372, Train Acc=0.0535\n",
      "Val Epoch: 0/20 val len: 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [04:43<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Val Loss=5.2052, Val Acc=0.0542\n",
      "Train Epoch: 1/20 train len: 918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [25:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=3.6052, Train Acc=0.1391\n",
      "Val Epoch: 1/20 val len: 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [04:43<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Loss=64.1542, Val Acc=0.0082\n",
      "Train Epoch: 2/20 train len: 918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 392/918 [10:59<14:57,  1.71s/it]"
     ]
    }
   ],
   "source": [
    "train_leaf(model, num_epochs, lr, device,best_acc)\n",
    "# torch.save(model.state_dict(), './working/leaf_resnet18.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-06-03T07:04:47.426598Z"
    }
   },
   "id": "6574693f915d9f27",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the test set of Leaves Dataset (8800 samples found)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 550/550 [04:34<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "saveFileName = './resnet18_raw/submission.csv'\n",
    "test_dataset = LeaveDataDataset(test_path, mode='test')\n",
    "test_iter = DataLoader(dataset=test_dataset,batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./working/leaf_resnet18.pth'))\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for X in tqdm(test_iter):\n",
    "    X = X.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)\n",
    "    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "\n",
    "preds = []\n",
    "for i in predictions:\n",
    "    preds.append(num_to_class[i])\n",
    "\n",
    "test_data = pd.read_csv(test_path)\n",
    "test_data['label'] = pd.Series(preds)\n",
    "submission = pd.concat([test_data['image'], test_data['label']], axis=1)\n",
    "submission.to_csv(saveFileName, index=False)\n",
    "print(\"Done!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T08:38:19.187345Z",
     "start_time": "2024-06-03T08:33:44.569908Z"
    }
   },
   "id": "70725f1809839646",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e3e8a38f3fb21e07"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
